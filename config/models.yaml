# Multi-Model Platform Configuration
# Supports: Anthropic, OpenAI, DeepSeek, Ollama, Gemini

providers:
  # Anthropic Claude Models
  anthropic:
    type: anthropic
    base_url: https://api.anthropic.com
    api_key_env: ANTHROPIC_API_KEY
    headers:
      anthropic-version: "2023-06-01"
    models:
      - claude-3-7-sonnet-latest
      - claude-3-7-haiku-latest
    embedding_models: []

  # OpenAI GPT Models
  openai:
    type: openai
    base_url: https://api.openai.com/v1
    api_key_env: OPENAI_API_KEY
    headers: {}
    models:
      - gpt-5
      - gpt-4
    embedding_models:
      - text-embedding-3-small
      - text-embedding-3-large
      - text-embedding-ada-002

  # DeepSeek Models
  deepseek:
    type: openai  # DeepSeek uses OpenAI-compatible API
    base_url: https://api.deepseek.com/v1
    api_key_env: DEEPSEEK_API_KEY
    headers: {}
    models:
      - deepseek-chat
      - deepseek-coder
    embedding_models: []

  # Ollama Local Models
  ollama:
    type: ollama
    base_url: http://localhost:11434  # Default Ollama port
    api_key_env: null  # No API key needed for local
    headers: {}
    models:
      - llama2
      - mistral
      # - mixtral
      # - phi
      # - neural-chat
      # - starling-lm
      # - orca-mini
      # - zephyr
    embedding_models:
      - nomic-embed-text
      - all-minilm

  # Google Gemini Models (optional)
  gemini:
    type: gemini
    base_url: https://generativelanguage.googleapis.com
    api_key_env: GEMINI_API_KEY
    headers: {}
    models:
      - gemini-pro
      - gemini-pro-vision
      - gemini-1.5-pro
      - gemini-1.5-flash
    embedding_models:
      - embedding-001

# Default settings
defaults:
  temperature: 0.7
  max_tokens: 8192
  timeout_seconds: 180